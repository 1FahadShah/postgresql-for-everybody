{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching Strategies to Reduce Database Load\n",
    "\n",
    "Before undertaking complex scaling solutions like replication or sharding, the most effective first step is almost always **caching**. Caching is the process of storing frequently accessed data in a faster, temporary storage layer (like memory) to avoid expensive database queries.\n",
    "\n",
    "A well-implemented cache can handle the vast majority of an application's read requests, dramatically reducing the load on the primary database.\n",
    "\n",
    "This notebook covers:\n",
    "1.  The core concept of caching.\n",
    "2.  The **Cache-Aside** pattern, the most common caching strategy.\n",
    "3.  A practical simulation of caching in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1. What is Caching?\n",
    "\n",
    "A database typically stores data on a disk (even a fast SSD), which is orders of magnitude slower than a computer's main memory (RAM). A cache is a simple key-value store that runs entirely in RAM.\n",
    "\n",
    "When an application needs data, it checks the cache first. If the data is there (a **cache hit**), it's returned almost instantly. If not (a **cache miss**), the application queries the database and then stores the result in the cache for next time.\n",
    "\n",
    "#### Analogy: The Workbench\n",
    "\n",
    "Think of your database as a large **toolbox** in the garage. Your in-memory cache is your **workbench** right next to you. If you need a hammer, you could walk to the toolbox every time. But if you're going to use the hammer frequently, it's much faster to keep it on your workbench. The first time you need it, you walk to the toolbox (a cache miss), but every subsequent time, you just grab it from the bench (a cache hit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular caching servers like **Redis** and **Memcached** are used for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. The Cache-Aside Pattern\n",
    "\n",
    "This is the most common caching strategy. The application code is responsible for managing the cache.\n",
    "\n",
    "### The Read Path\n",
    "1.  Your application receives a request for data (e.g., a user's profile).\n",
    "2.  It checks the cache for the corresponding key (e.g., `user:123`).\n",
    "3.  **Cache Hit**: If the data is in the cache, it's returned immediately. The database is not involved.\n",
    "4.  **Cache Miss**: If the data is not in the cache, the application queries the database, gets the result, **stores the result in the cache**, and then returns it.\n",
    "\n",
    "### The Write Path (Cache Invalidation)\n",
    "1.  Your application receives a request to update data.\n",
    "2.  It sends the `UPDATE` or `DELETE` command directly to the **database** (the source of truth).\n",
    "3.  After the database confirms the write, the application sends a command to the cache to **DELETE** the old, stale entry. \n",
    "\n",
    "This ensures that the next time the data is requested, it will be a cache miss, forcing a read from the database to get the fresh data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 3. Practical Simulation in Python\n",
    "\n",
    "Let's simulate this pattern using simple Python dictionaries to represent our cache and database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CACHE MISS] user:101 not in cache. Querying database...\n",
      "   - Populating cache with user:101.\n",
      "Request 1 for user 101: {'name': 'Fahad', 'email': 'fahad@example.com'}\n",
      "\n",
      "[CACHE HIT] Found user:101 in cache.\n",
      "Request 2 for user 101: {'name': 'Fahad', 'email': 'fahad@example.com'}\n",
      "\n",
      "--- Updating email for user:101 in database ---\n",
      "   - Invalidating user:101 from cache.\n",
      "[CACHE MISS] user:101 not in cache. Querying database...\n",
      "   - Populating cache with user:101.\n",
      "\n",
      "Request 3 for user 101: {'name': 'Fahad', 'email': 'fahad.shah@new.com'}\n",
      "\n",
      "[CACHE HIT] Found user:101 in cache.\n",
      "Request 4 for user 101: {'name': 'Fahad', 'email': 'fahad.shah@new.com'}\n"
     ]
    }
   ],
   "source": [
    "# Our 'slow' database, represented as a dictionary\n",
    "database = {\n",
    "    'user:101': {'name': 'Fahad', 'email': 'fahad@example.com'},\n",
    "    'user:102': {'name': 'Alice', 'email': 'alice@example.com'}\n",
    "}\n",
    "\n",
    "# Our 'fast' in-memory cache, also a dictionary\n",
    "cache = {}\n",
    "\n",
    "def get_user(user_id):\n",
    "    key = f'user:{user_id}'\n",
    "    \n",
    "    # 1. Check the cache first\n",
    "    if key in cache:\n",
    "        print(f\"[CACHE HIT] Found {key} in cache.\")\n",
    "        return cache[key]\n",
    "    \n",
    "    # 2. If not in cache, it's a miss. Go to the database.\n",
    "    print(f\"[CACHE MISS] {key} not in cache. Querying database...\")\n",
    "    data = database.get(key)\n",
    "    \n",
    "    # 3. Store the result in the cache for next time\n",
    "    if data:\n",
    "        print(f\"   - Populating cache with {key}.\")\n",
    "        cache[key] = data\n",
    "        \n",
    "    return data\n",
    "\n",
    "def update_user_email(user_id, new_email):\n",
    "    key = f'user:{user_id}'\n",
    "    \n",
    "    # 1. Update the database (source of truth)\n",
    "    if key in database:\n",
    "        print(f\"\\n--- Updating email for {key} in database ---\")\n",
    "        database[key]['email'] = new_email\n",
    "        \n",
    "        # 2. Invalidate (delete) the entry from the cache\n",
    "        if key in cache:\n",
    "            print(f\"   - Invalidating {key} from cache.\")\n",
    "            del cache[key]\n",
    "\n",
    "# --- Let's run the simulation ---\n",
    "\n",
    "# First request for user 101: MISS\n",
    "print(f\"Request 1 for user 101: {get_user(101)}\\n\")\n",
    "\n",
    "# Second request for user 101: HIT\n",
    "print(f\"Request 2 for user 101: {get_user(101)}\")\n",
    "\n",
    "# Update the user's email in the database\n",
    "update_user_email(101, 'fahad.shah@new.com')\n",
    "\n",
    "# Third request for user 101: MISS (because it was invalidated)\n",
    "print(f\"\\nRequest 3 for user 101: {get_user(101)}\\n\")\n",
    "\n",
    "# Fourth request for user 101: HIT (with the new data)\n",
    "print(f\"Request 4 for user 101: {get_user(101)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 4. Caching Challenges\n",
    "\n",
    "While powerful, caching introduces its own set of challenges:\n",
    "\n",
    "- **Cache Invalidation**: This is famously one of the hardest problems in computer science. Deciding when and how to remove stale data from the cache is complex.\n",
    "- **Cache Eviction**: What happens when the cache is full? An eviction policy (like **LRU - Least Recently Used**) must decide which items to discard to make room for new ones.\n",
    "- **Cold Start**: When an application restarts, the cache is empty. The initial storm of requests will all miss and hit the database, which can cause performance issues. This is often solved with a cache \"warm-up\" process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Conclusion\n",
    "\n",
    "Caching is the most impactful first step in scaling an application. By serving the majority of read requests from a fast in-memory store, it dramatically reduces the load on the primary database.\n",
    "\n",
    "It often delays or even eliminates the need for more complex and expensive scaling solutions like replication or sharding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 3, Module 3: Advanced Techniques and Best Practices\n",
    "\n",
    "This final notebook covers advanced topics and best practices that are essential for building robust, scalable, and maintainable applications with Python and PostgreSQL.\n",
    "\n",
    "We will explore:\n",
    "1.  **Proper Error Handling**: How to catch and inspect specific database errors.\n",
    "2.  **Bulk Operations**: The efficient way to insert many rows of data at once using `executemany()`.\n",
    "3.  **Calling Stored Procedures**: How to execute server-side logic from your Python application.\n",
    "4.  **Connection Pooling (Conceptual)**: Understanding why connection pooling is critical for performance in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Setup\n",
    "\n",
    "We'll import `psycopg2` and `time` for a performance test, then define our connection details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"people\"\n",
    "DB_USER = \"fahad\"\n",
    "DB_PASS = \"secret\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1. Proper Error Handling\n",
    "\n",
    "So far, we've caught generic `psycopg2.Error`. However, `psycopg2` provides specific exception types, allowing you to handle different errors in different ways. A common example is trying to insert a duplicate value into a column with a `UNIQUE` constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reuse the 'users' table which has a UNIQUE constraint on username\n",
    "sql_insert = \"INSERT INTO users (username, password) VALUES (%s, %s);\"\n",
    "\n",
    "try:\n",
    "    with psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_PASS) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            # This first insert will work\n",
    "            cur.execute(sql_insert, ('testuser', 'testpass'))\n",
    "            print(\"First insert successful.\")\n",
    "            \n",
    "            # This second one will fail because 'testuser' is already taken\n",
    "            cur.execute(sql_insert, ('testuser', 'anotherpass'))\n",
    "            print(\"Second insert successful.\") # This line will not be reached\n",
    "except psycopg2.Error as e:\n",
    "    # psycopg2.errors.UniqueViolation is the specific error for this case\n",
    "    if e.pgcode == '23505': # '23505' is the PostgreSQL code for unique_violation\n",
    "        print(f\"Error: The username 'testuser' already exists. Please choose another.\")\n",
    "        conn.rollback() # Roll back the failed transaction\n",
    "    else:\n",
    "        print(f\"A different database error occurred: {e}\")\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2. Bulk Operations with `executemany()`\n",
    "\n",
    "Inserting thousands of rows one at a time in a loop is very slow because of the network round-trip for each `execute()` call. `executemany()` is far more efficient as it sends the data in a single batch.\n",
    "\n",
    "Let's create a table and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_setup = \"\"\"\n",
    "DROP TABLE IF EXISTS perf_test CASCADE;\n",
    "CREATE TABLE perf_test (\n",
    "    id INT,\n",
    "    name TEXT\n",
    ");\n",
    "\"\"\"\n",
    "with psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_PASS) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(sql_setup)\n",
    "print(\"Table 'perf_test' created.\")\n",
    "\n",
    "# Prepare a large list of data to insert\n",
    "data_to_insert = [(i, f'User {i}') for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Testing slow method: loop with execute() ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "with psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_PASS) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        for record in data_to_insert:\n",
    "            cur.execute(\"INSERT INTO perf_test (id, name) VALUES (%s, %s);\", record)\n",
    "    conn.commit()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Looping with execute() took: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the table first\n",
    "with psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_PASS) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"DELETE FROM perf_test;\")\n",
    "\n",
    "print(\"--- Testing fast method: executemany() ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "with psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_PASS) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.executemany(\"INSERT INTO perf_test (id, name) VALUES (%s, %s);\", data_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Using executemany() took: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance difference is dramatic. `executemany()` is the correct choice for bulk inserts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 3. Calling Stored Procedures\n",
    "\n",
    "You can execute server-side logic (stored procedures/functions) from Python. This is useful for encapsulating complex business logic in the database.\n",
    "\n",
    "Let's create a simple function to count employees and call it from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_function = \"\"\"\n",
    "CREATE OR REPLACE FUNCTION get_user_count() RETURNS BIGINT AS $$\n",
    "BEGIN\n",
    "    RETURN (SELECT COUNT(*) FROM users);\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\"\"\"\n",
    "\n",
    "with psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_PASS) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(sql_function)\n",
    "print(\"Stored function 'get_user_count' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg2.connect(host=DB_HOST, dbname=DB_NAME, user=DB_USER, password=DB_PASS) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # The correct way to call a function is with SELECT\n",
    "        cur.execute(\"SELECT get_user_count();\")\n",
    "        user_count = cur.fetchone()[0]\n",
    "        print(f\"The stored function reported {user_count} users.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 4. Connection Pooling (Conceptual)\n",
    "\n",
    "In a real-world application like a web server, you might get hundreds of requests per second. Opening and closing a new database connection for every single request is extremely slow and inefficient. The process of establishing a connection (TCP handshake, authentication) is expensive.\n",
    "\n",
    "The solution is **Connection Pooling**. A pool is a cache of pre-connected, ready-to-use database connections. When your application needs to talk to the database, it quickly \"borrows\" a connection from the pool and \"returns\" it when done. This avoids the expensive connection setup process on every request.\n",
    "\n",
    "`psycopg2` has a built-in connection pool (`psycopg2.pool`) that is essential for any multi-threaded application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Conclusion\n",
    "\n",
    "This notebook covered key techniques for writing professional-grade database code:\n",
    "\n",
    "1.  **Handle errors specifically** by catching `psycopg2.Error` and inspecting its properties.\n",
    "2.  Use **`executemany()`** for significant performance gains when inserting large amounts of data.\n",
    "3.  Encapsulate logic in the database by **calling stored procedures** from Python.\n",
    "4.  Understand the necessity of **connection pooling** for scalable applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
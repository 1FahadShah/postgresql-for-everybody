{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Building an Inverted Index\n",
    "\n",
    "This notebook bridges the gap between basic B-Tree indexes and advanced text search. We will manually construct an **Inverted Index** (also known as a Reverse Index), the fundamental data structure behind all modern search engines.\n",
    "\n",
    "An inverted index does not store data in a sorted order of its primary key. Instead, it creates a dictionary-like structure where the \"keys\" are the words (tokens) found in the documents, and the \"values\" are lists of document IDs where those words appear.\n",
    "\n",
    "We will:\n",
    "1. Create tables to store documents and our index.\n",
    "2. **Tokenize** documents into individual words.\n",
    "3. Populate the index by mapping each word to the document(s) containing it.\n",
    "4. Use our index to perform a simple text search and understand its limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Setup\n",
    "\n",
    "As always, we load the `ipython-sql` extension and connect to our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://fahad:secret@localhost:5432/people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Step 1: Schema and Data Setup\n",
    "\n",
    "We need two tables:\n",
    "- `docs03`: To store the original text documents. Each document gets a unique ID.\n",
    "- `invert03`: Our inverted index. This table will store a `keyword` and the `doc_id` it appears in. A many-to-many relationship exists between keywords and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://fahad:***@localhost:5432/people\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS invert03;\n",
    "DROP TABLE IF EXISTS docs03;\n",
    "\n",
    "CREATE TABLE docs03 (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    doc TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE invert03 (\n",
    "    keyword TEXT,\n",
    "    doc_id INTEGER REFERENCES docs03(id) ON DELETE CASCADE\n",
    ");\n",
    "\n",
    "-- Insert some sample documents to index\n",
    "INSERT INTO docs03 (doc) VALUES\n",
    "('PostgreSQL is a powerful open source relational database'),\n",
    "('We can use SQL to query the database and retrieve data'),\n",
    "('Full-text search is a powerful feature of PostgreSQL');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Step 2: Tokenize and Populate the Index\n",
    "\n",
    "This is the core of the process. We'll read each document, split it into lowercase words (tokens), and insert a row into `invert03` for each word. We use the `regexp_split_to_table` function, which is perfect for this tokenization task, just as we did in our course assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://fahad:***@localhost:5432/people\n",
      "27 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "INSERT INTO invert03 (keyword, doc_id)\n",
    "SELECT LOWER(word), d.id\n",
    "FROM docs03 AS d, regexp_split_to_table(d.doc, '\\s+') AS word;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the contents of our new index. Notice how each word is listed alongside the ID of the document it came from. The word `database` appears in documents 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://fahad:***@localhost:5432/people\n",
      "15 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>keyword</th>\n",
       "            <th>doc_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>a</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>a</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>and</td>\n",
       "            <td>2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>can</td>\n",
       "            <td>2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>data</td>\n",
       "            <td>2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>database</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>database</td>\n",
       "            <td>2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>feature</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>full-text</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>is</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>is</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>of</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>open</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>postgresql</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>postgresql</td>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('a', 1),\n",
       " ('a', 3),\n",
       " ('and', 2),\n",
       " ('can', 2),\n",
       " ('data', 2),\n",
       " ('database', 1),\n",
       " ('database', 2),\n",
       " ('feature', 3),\n",
       " ('full-text', 3),\n",
       " ('is', 1),\n",
       " ('is', 3),\n",
       " ('of', 3),\n",
       " ('open', 1),\n",
       " ('postgresql', 1),\n",
       " ('postgresql', 3)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM invert03 ORDER BY keyword, doc_id LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Step 3: Using the Inverted Index for Search\n",
    "\n",
    "Now that the index is built, finding documents containing a specific word is incredibly efficient. Instead of scanning the full text of every document (`Seq Scan`), we can directly query our `invert03` table.\n",
    "\n",
    "First, we find the IDs of all documents that contain our search term (e.g., 'powerful')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://fahad:***@localhost:5432/people\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>doc_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1,), (3,)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT doc_id FROM invert03 WHERE keyword = 'powerful';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we use those IDs to retrieve the full text of the matching documents from the original `docs03` table. An `INNER JOIN` is the most efficient and readable way to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://fahad:***@localhost:5432/people\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th>\n",
       "            <th>doc</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "            <td>PostgreSQL is a powerful open source relational database</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "            <td>Full-text search is a powerful feature of PostgreSQL</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, 'PostgreSQL is a powerful open source relational database'),\n",
       " (3, 'Full-text search is a powerful feature of PostgreSQL')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "-- Find all documents that contain the word 'powerful'\n",
    "SELECT T2.id, T2.doc FROM invert03 AS T1 \n",
    "JOIN docs03 AS T2 ON T1.doc_id = T2.id\n",
    "WHERE T1.keyword = 'powerful';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Limitations of the Manual Approach\n",
    "\n",
    "While this demonstrates the concept perfectly, our manual index is very basic and not suitable for real-world applications. It doesn't handle:\n",
    "\n",
    "- **Punctuation**: Words like `'database.'` are not treated the same as `'database'`.\n",
    "- **Stemming**: A search for `'query'` won't find the related word `'querying'`.\n",
    "- **Ranking**: All matches are treated equally. We can't tell which document is a *better* or more relevant match.\n",
    "- **Stop Words**: Common words like 'is', 'a', 'the' clutter the index and are meaningless for search. We would have to filter them out manually.\n",
    "- **Performance**: A simple `(keyword, doc_id)` table is not optimized. A B-Tree on `keyword` would help, but PostgreSQL offers even better solutions.\n",
    "\n",
    "This is precisely why PostgreSQL has a built-in Full-Text Search (FTS) engine, which solves all these problems. We will explore it in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we successfully built a functional inverted index from scratch. We learned that an inverted index is a mapping from **terms (keywords) to the documents** that contain them. This is a fundamental shift from a traditional index, which maps a **primary key to its data**.\n",
    "\n",
    "Understanding this manual approach is the key to appreciating PostgreSQL's sophisticated, built-in FTS capabilities, which automate and optimize this entire process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
